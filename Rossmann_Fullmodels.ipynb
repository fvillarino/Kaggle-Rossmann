{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Rossmann-Fullmodels.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillarino/Kaggle-Rossmann/blob/master/Rossmann_Fullmodels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loved-southwest"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "id": "loved-southwest",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiscal-tiger"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "id": "fiscal-tiger",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auburn-slovak"
      },
      "source": [
        "#### Datos normalizados"
      ],
      "id": "auburn-slovak"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yAxrYhO2vPw",
        "outputId": "5b3a6bb0-0c0b-4d64-9c76-ade32b5ae7fe"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "folder='drive/MyDrive/Colab Notebooks/Kaggle/Rossman/'\r\n",
        "drive.mount('/content/drive')"
      ],
      "id": "2yAxrYhO2vPw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "native-uganda"
      },
      "source": [
        "df = pd.read_feather(folder+'train_normalized_data.fth')\n",
        "df_test = pd.read_feather(folder+'test_normalized_data.fth')"
      ],
      "id": "native-uganda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuclear-pierce"
      },
      "source": [
        "#### Separo categoricas y continuas"
      ],
      "id": "nuclear-pierce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miniature-organ"
      },
      "source": [
        "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', \n",
        "            'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', \n",
        "            'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_bool_fw', 'StateHoliday_bool_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw']"
      ],
      "id": "miniature-organ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leading-joshua"
      },
      "source": [
        "contin_vars = ['CompetitionDistance', \n",
        "   'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Precipitationmm',\n",
        "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
        "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
        "   'AfterStateHoliday_bool', 'BeforeStateHoliday_bool', 'Promo', 'SchoolHoliday', 'StateHoliday_bool']"
      ],
      "id": "leading-joshua",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recorded-coupon"
      },
      "source": [
        "y_out_columns = ['Sales']"
      ],
      "id": "recorded-coupon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "molecular-seafood"
      },
      "source": [
        "### LightGBM"
      ],
      "id": "molecular-seafood"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stone-designation"
      },
      "source": [
        "#### Split de datos para entrenar"
      ],
      "id": "stone-designation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lined-benjamin"
      },
      "source": [
        "# split_type = 'random'\n",
        "# split_type = 'no_split'\n",
        "split_type = 'last_week'"
      ],
      "id": "lined-benjamin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raised-wheat",
        "outputId": "08d3100d-3c9d-47b4-f31f-632cf7da2625"
      },
      "source": [
        "if split_type == 'no_split':\n",
        "    df_train = df\n",
        "elif split_type == 'last_week':\n",
        "    # Esto divide en train y val\n",
        "    df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
        "    df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]\n",
        "    print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_val)/(len(df_train) + len(df_val))}')\n",
        "elif split_type == 'random':\n",
        "    # Splitting aleatorio\n",
        "    np.random.seed(42)\n",
        "    indexes = np.arange(len(df))\n",
        "    np.random.shuffle(indexes)\n",
        "    N = len(df)//5\n",
        "    df_train = df[N:]\n",
        "    df_val = df[:N]\n",
        "    print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_val)/(len(df_train) + len(df_val))}')"
      ],
      "id": "raised-wheat",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad en val: 30188, porcentaje: 0.035753454185409164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utility-sunrise"
      },
      "source": [
        "X_train = df_train[cat_vars + contin_vars]\n",
        "if split_type != 'no_split':\n",
        "    X_val = df_val[cat_vars + contin_vars]\n",
        "X_test = df_test[cat_vars + contin_vars]"
      ],
      "id": "utility-sunrise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appreciated-broadway"
      },
      "source": [
        "#### Normalización de los datos"
      ],
      "id": "appreciated-broadway"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "focal-throw"
      },
      "source": [
        "log_output = False\n",
        "    \n",
        "if log_output:\n",
        "    # Escala logaritmica\n",
        "    max_log_y = np.max(np.log(df[y_out_columns])).values\n",
        "    y_train = np.log(df_train[y_out_columns].values)/max_log_y\n",
        "    if split_type != 'no_split':\n",
        "        y_val = np.log(df_val[y_out_columns].values)/max_log_y\n",
        "else:\n",
        "    # Normalización\n",
        "    y_mean = df_train[y_out_columns].mean().values\n",
        "    y_std = df_train[y_out_columns].std().values\n",
        "    y_train = (df_train[y_out_columns].values - y_mean)/y_std\n",
        "    if split_type != 'no_split':\n",
        "        y_val = (df_val[y_out_columns].values - y_mean)/y_std"
      ],
      "id": "focal-throw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intense-curve"
      },
      "source": [
        "#### Armado del modelo"
      ],
      "id": "intense-curve"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medical-honor"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from hyperopt import hp, tpe\n",
        "from hyperopt.fmin import fmin\n",
        "from lightgbm import LGBMRegressor"
      ],
      "id": "medical-honor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "demanding-approval"
      },
      "source": [
        "def calculate_RMSE(X, y, log_output=True):\n",
        "    y_preds = np.exp(model.predict(X, verbose=1)*max_log_y)\n",
        "    return np.sqrt((((y - y_preds)/y)**2).sum()/len(y_preds))"
      ],
      "id": "demanding-approval",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dated-diabetes"
      },
      "source": [
        "min_child_samples=5\n",
        "n_estimators=2000\n",
        "learning_rate=0.25\n",
        "model = LGBMRegressor(min_child_samples=min_child_samples, n_estimators=n_estimators, learning_rate=learning_rate )"
      ],
      "id": "dated-diabetes",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "immediate-documentary"
      },
      "source": [
        "fit_params={\"early_stopping_rounds\":100, \n",
        "            \"eval_metric\" : 'l2', \n",
        "            \"eval_set\" : [(X_val, y_val.reshape(-1))],\n",
        "            'eval_names': ['valid'],\n",
        "            'verbose': 100,\n",
        "            'feature_name': 'auto', # that's actually the default\n",
        "            'categorical_feature': cat_vars\n",
        "           }"
      ],
      "id": "immediate-documentary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nutritional-attribute",
        "outputId": "6e7545b3-b675-4881-b4f4-dfd405239671"
      },
      "source": [
        "model.fit(X_train, y_train.reshape(-1), **fit_params)"
      ],
      "id": "nutritional-attribute",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
            "New categorical_feature is ['Assortment', 'CompetitionMonthsOpen', 'CompetitionOpenSinceYear', 'Day', 'DayOfWeek', 'Events', 'Month', 'Promo2SinceYear', 'Promo2Weeks', 'PromoInterval', 'Promo_bw', 'Promo_fw', 'SchoolHoliday_bw', 'SchoolHoliday_fw', 'State', 'StateHoliday', 'StateHoliday_bool_bw', 'StateHoliday_bool_fw', 'Store', 'StoreType', 'Week', 'Year']\n",
            "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid's l2: 0.100789\tvalid's l2: 0.100789\n",
            "[200]\tvalid's l2: 0.0959811\tvalid's l2: 0.0959811\n",
            "[300]\tvalid's l2: 0.097763\tvalid's l2: 0.097763\n",
            "Early stopping, best iteration is:\n",
            "[212]\tvalid's l2: 0.0943812\tvalid's l2: 0.0943812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.25, max_depth=-1,\n",
              "              min_child_samples=5, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=2000, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "substantial-greene"
      },
      "source": [
        "#### Análisis de la métrica"
      ],
      "id": "substantial-greene"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubber-corpus",
        "outputId": "74e205d3-dc91-4492-885e-cbd1543a079b"
      },
      "source": [
        "model.score(X_val, y_val)"
      ],
      "id": "rubber-corpus",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.894198929653378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "certified-venezuela"
      },
      "source": [
        "if log_output:\n",
        "    y_pred_train = np.exp(model.predict(X_train, verbose=1)*max_log_y)\n",
        "    y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
        "    y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)\n",
        "else:\n",
        "    y_pred_train = model.predict(X_train, verbose=1)*y_std + y_mean\n",
        "    y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
        "    y_pred_test = model.predict(X_test, verbose=1)*y_std + y_mean"
      ],
      "id": "certified-venezuela",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tribal-holly",
        "outputId": "98953f4c-f6ad-47e8-efed-e441d5740012"
      },
      "source": [
        "# Train\n",
        "np.sqrt((((df_train['Sales'].values - y_pred_train)/df_train['Sales'].values)**2).sum()/len(y_pred_train))"
      ],
      "id": "tribal-holly",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17867032619235249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "straight-american",
        "outputId": "f274fd1c-9e18-4e64-eb16-16335c14b05e"
      },
      "source": [
        "# Validación\n",
        "np.sqrt((((df_val['Sales'].values - y_pred)/df_val['Sales'].values)**2).sum()/len(y_pred))"
      ],
      "id": "straight-american",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14613309144773187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worst-fight"
      },
      "source": [
        "#### LightGBM con Hyperopt"
      ],
      "id": "worst-fight"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "polar-cancellation"
      },
      "source": [
        "def predicctionDesNormalizacion(model, soloVal=False):\n",
        "  if log_output:\n",
        "      if soloVal:\n",
        "        y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
        "      else:\n",
        "        y_pred_train = np.exp(model.predict(X_train, verbose=1)*max_log_y)\n",
        "        y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
        "        y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)\n",
        "  else:\n",
        "      if soloVal:\n",
        "        y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
        "      else:\n",
        "        y_pred_train = model.predict(X_train, verbose=1)*y_std + y_mean\n",
        "        y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
        "        y_pred_test = model.predict(X_test, verbose=1)*y_std + y_mean\n",
        "  if soloVal:\n",
        "    return y_pred\n",
        "  return y_pred_train, y_pred, y_pred_test"
      ],
      "id": "polar-cancellation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acute-welsh"
      },
      "source": [
        "from hyperopt import hp, tpe\n",
        "from hyperopt.fmin import fmin\n",
        "from hyperopt import Trials\n",
        "import hyperopt"
      ],
      "id": "acute-welsh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "separated-nelson"
      },
      "source": [
        "search_HyperOptSearch = {\n",
        "    'learning_rate': hp.loguniform(low=0.01, high=1, label='learning_rate'),\n",
        "    'max_depth':  hp.choice('max_depth', list(np.arange(5, 20))),\n",
        "    #'num_leaves': hp.choice('num_leaves', list(np.arange(2, 150))), #max number of leaves in one tree        \n",
        "    #'min_child_samples': hp.choice('min_child_samples', list(np.arange(0, 200))), # minimal number of data in one leaf\n",
        "    #'reg_lambda': hp.loguniform('reg_lambda',1e-9, 1000), # L2 regularization\n",
        "    #'reg_alpha': hp.loguniform('reg_alpha',1e-9, 1.0), # L1 regularization\n",
        "    #'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0), # enabler of bagging fraction\n",
        "    #'min_child_weight': hp.choice('min_child_weight', list(np.arange(0, 10,))), # minimal number of data in one leaf.\n",
        "    'n_estimators': hp.choice('n_estimators', list(np.arange(900, 1000))) # cant. de estimadores secuenciales (se pone alto stopea earlystopping)    \n",
        "}\n",
        "max_iterSearch = 100"
      ],
      "id": "separated-nelson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quarterly-humor",
        "outputId": "7d875ad8-d5dd-40a2-9d87-41638e7d2c25"
      },
      "source": [
        "def objective(params):\n",
        "        \n",
        "    clf = LGBMRegressor(**params)    \n",
        "    score = -cross_val_score(clf, X_train.values, y_train.reshape(-1), cv=4, scoring='neg_root_mean_squared_error', verbose=1).mean()\n",
        "    return score\n",
        "\n",
        "tpe_trials = Trials()    \n",
        "\n",
        "\n",
        "%time hyperOptLightGBM = fmin(fn=objective, space=search_HyperOptSearch, verbose=2, algo=hyperopt.tpe.suggest, max_evals=max_iterSearch)"
      ],
      "id": "quarterly-humor",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [04:19<7:07:47, 259.27s/it, best loss: 0.5641907040185502]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.3min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [09:33<7:30:10, 275.62s/it, best loss: 0.5641907040185502]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [14:11<7:26:52, 276.42s/it, best loss: 0.5641907040185502]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.6min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [18:21<7:09:34, 268.49s/it, best loss: 0.46570635083792744]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [21:17<6:21:19, 240.84s/it, best loss: 0.46570635083792744]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.9min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [26:06<6:39:50, 255.22s/it, best loss: 0.46570635083792744]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.8min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [30:22<6:36:08, 255.57s/it, best loss: 0.46570635083792744]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.3min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [34:14<6:20:59, 248.47s/it, best loss: 0.4233910643939531] "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.9min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [37:31<5:53:13, 232.90s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.3min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [42:37<6:22:22, 254.91s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.1min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [46:50<6:17:14, 254.32s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [50:09<5:48:34, 237.66s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.3min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [54:17<5:49:12, 240.83s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [59:28<6:15:18, 261.85s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [1:03:00<5:49:37, 246.79s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.5min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [1:06:43<5:35:33, 239.68s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.7min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [1:10:13<5:19:32, 230.99s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.5min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [1:13:07<4:52:04, 213.72s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.9min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [1:16:29<4:43:59, 210.37s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.4min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [1:20:26<4:51:10, 218.39s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.0min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [1:24:40<5:01:25, 228.94s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [1:29:28<5:20:50, 246.81s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.8min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [1:33:29<5:14:14, 244.86s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.0min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [1:37:35<5:10:30, 245.14s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [1:44:04<6:00:25, 288.34s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.5min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [1:48:13<5:41:14, 276.69s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [1:52:22<5:26:28, 268.33s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [1:57:05<5:27:05, 272.57s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.7min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [2:04:14<6:18:20, 319.72s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.2min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [2:09:08<6:03:46, 311.80s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.9min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [2:13:12<5:35:22, 291.63s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.1min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [2:17:56<5:27:43, 289.17s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.7min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [2:21:56<5:06:30, 274.49s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.0min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [2:26:48<5:07:53, 279.91s/it, best loss: 0.4233910643939531]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.9min finished\n",
            "\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "initial-dancing"
      },
      "source": [
        "print('best parameters:', hyperOptLightGBM)"
      ],
      "id": "initial-dancing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "african-penguin"
      },
      "source": [
        "model = LGBMRegressor(**hyperOptLightGBM)\n",
        "model.fit(X_train, y_train.reshape(-1), **fit_params)\n",
        "y_pred_train, y_pred, y_pred_test = predicctionDesNormalizacion(model)\n",
        "\n",
        "print('RMSE en train:',np.sqrt((((df_train['Sales'].values - y_pred_train)/df_train['Sales'].values)**2).sum()/len(y_pred_train)))\n",
        "print('RMSE en val:', np.sqrt((((df_val['Sales'].values - y_pred)/df_val['Sales'].values)**2).sum()/len(y_pred)))"
      ],
      "id": "african-penguin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIiY-tHWDlHM"
      },
      "source": [
        ""
      ],
      "id": "gIiY-tHWDlHM",
      "execution_count": null,
      "outputs": []
    }
  ]
}