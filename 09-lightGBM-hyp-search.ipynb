{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=1-NYPQw5THU&feature=youtu.be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_normalized_data.fth')\n",
    "df_test = pd.read_feather('test_normalized_data.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', \n",
    "            'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', \n",
    "            'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_bool_fw', 'StateHoliday_bool_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "\n",
    "# cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'State']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_vars = ['CompetitionDistance', \n",
    "   'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Precipitationmm',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "   'AfterStateHoliday_bool', 'BeforeStateHoliday_bool', 'Promo', 'SchoolHoliday', 'StateHoliday_bool']\n",
    "# contin_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_columns = ['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_type = 'random'\n",
    "# split_type = 'no_split'\n",
    "split_type = 'last_week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad en val: 30029, porcentaje: 0.9638795367092596\n"
     ]
    }
   ],
   "source": [
    "# Esta es para entrenar con todo\n",
    "if split_type == 'no_split':\n",
    "    df_train = df\n",
    "elif split_type == 'last_week':\n",
    "    # Esto divide en train y val\n",
    "    df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
    "    df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]\n",
    "    print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_train)/(len(df_train) + len(df_val))}')\n",
    "elif split_type == 'random':\n",
    "    # Splitting aleatorio\n",
    "    np.random.seed(42)\n",
    "    indexes = np.arange(len(df))\n",
    "    np.random.shuffle(indexes)\n",
    "    N = len(df)//5\n",
    "    df_train = df[N:]\n",
    "    df_val = df[:N]\n",
    "    print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_train)/(len(df_train) + len(df_val))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[cat_vars + contin_vars]\n",
    "if split_type != 'no_split':\n",
    "    X_val = df_val[cat_vars + contin_vars]\n",
    "X_test = df_test[cat_vars + contin_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_output = False\n",
    "    \n",
    "if log_output:\n",
    "    # Escala logaritmica\n",
    "    max_log_y = np.max(np.log(df[y_out_columns])).values\n",
    "    y_train = np.log(df_train[y_out_columns].values)/max_log_y\n",
    "    if split_type != 'no_split':\n",
    "        y_val = np.log(df_val[y_out_columns].values)/max_log_y\n",
    "else:\n",
    "    # Normalización\n",
    "    y_mean = df_train[y_out_columns].mean().values\n",
    "    y_std = df_train[y_out_columns].std().values\n",
    "    y_train = (df_train[y_out_columns].values - y_mean)/y_std\n",
    "    if split_type != 'no_split':\n",
    "        y_val = (df_val[y_out_columns].values - y_mean)/y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(X, y, log_output=True):\n",
    "    y_preds = np.exp(model.predict(X, verbose=1)*max_log_y)\n",
    "    return np.sqrt((((y - y_preds)/y)**2).sum()/len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801328, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        # 'max_depth': int(params['max_depth']),\n",
    "        # 'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'learning_rate': '{:.4f}'.format(params['learning_rate'])\n",
    "    }\n",
    "    \n",
    "    clf = LGBMRegressor(\n",
    "        n_estimators=4000,\n",
    "        min_child_samples= 5, max_depth= -1,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = -cross_val_score(clf, X_train.values, y_train.reshape(-1)).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 10/10 [1:18:34<00:00, 471.46s/trial, best loss: -0.9157219223685406]\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    # 'max_depth': hp.quniform('max_depth', 1, 64, 4),\n",
    "    # 'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -4, -2)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            verbose=2,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.122458397489952}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate':[0.001, 0.05, 0.1, 0.5], 'max_depth':[1, 7, 31, 63]}\n",
    "grid_search_res_1 = {'learning_rate': 0.05, 'min_child_samples': 5, 'max_depth': -1}\n",
    "grid_search_res_2 = {'learning_rate': 0.05, 'max_depth': 7, 'min_child_samples': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_samples = 5\n",
    "n_estimators = 4000\n",
    "learning_rate = 0.1\n",
    "model = LGBMRegressor(n_estimators=n_estimators, **grid_search_res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, parameters, n_jobs=-1, verbose=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={ \"eval_metric\" : 'l2', \n",
    "            'verbose': 100,\n",
    "            'feature_name': 'auto', # that's actually the default\n",
    "            'categorical_feature': cat_vars}\n",
    "if split_type != 'no_split':\n",
    "    fit_params[\"eval_set\"] = [(X_val, y_val.reshape(-1))]\n",
    "    fit_params[\"early_stopping_rounds\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fvillarino\\Anaconda3\\envs\\dip-ml-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\fvillarino\\Anaconda3\\envs\\dip-ml-env\\lib\\site-packages\\lightgbm\\basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Assortment', 'CompetitionMonthsOpen', 'CompetitionOpenSinceYear', 'Day', 'DayOfWeek', 'Events', 'Month', 'Promo2SinceYear', 'Promo2Weeks', 'PromoInterval', 'Promo_bw', 'Promo_fw', 'SchoolHoliday_bw', 'SchoolHoliday_fw', 'State', 'StateHoliday', 'StateHoliday_bool_bw', 'StateHoliday_bool_fw', 'Store', 'StoreType', 'Week', 'Year']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fvillarino\\Anaconda3\\envs\\dip-ml-env\\lib\\site-packages\\lightgbm\\basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\fvillarino\\Anaconda3\\envs\\dip-ml-env\\lib\\site-packages\\lightgbm\\basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 0.185293\n",
      "[200]\tvalid_0's l2: 0.123128\n",
      "[300]\tvalid_0's l2: 0.0979951\n",
      "[400]\tvalid_0's l2: 0.0882945\n",
      "[500]\tvalid_0's l2: 0.0832867\n",
      "[600]\tvalid_0's l2: 0.0808044\n",
      "[700]\tvalid_0's l2: 0.0781941\n",
      "[800]\tvalid_0's l2: 0.0767965\n",
      "[900]\tvalid_0's l2: 0.0756286\n",
      "[1000]\tvalid_0's l2: 0.0748416\n",
      "[1100]\tvalid_0's l2: 0.073819\n",
      "[1200]\tvalid_0's l2: 0.0733017\n",
      "[1300]\tvalid_0's l2: 0.072656\n",
      "[1400]\tvalid_0's l2: 0.07198\n",
      "[1500]\tvalid_0's l2: 0.0716238\n",
      "[1600]\tvalid_0's l2: 0.0713572\n",
      "[1700]\tvalid_0's l2: 0.0709648\n",
      "[1800]\tvalid_0's l2: 0.0707657\n",
      "[1900]\tvalid_0's l2: 0.0703391\n",
      "[2000]\tvalid_0's l2: 0.0702146\n",
      "[2100]\tvalid_0's l2: 0.0699909\n",
      "[2200]\tvalid_0's l2: 0.0698631\n",
      "[2300]\tvalid_0's l2: 0.0697974\n",
      "Early stopping, best iteration is:\n",
      "[2292]\tvalid_0's l2: 0.0697789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.05, max_depth=7, n_estimators=4000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.fit(X_train, y_train.reshape(-1), **fit_params)\n",
    "model.fit(X_train, y_train.reshape(-1), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMRegressor(learning_rate=0.05, max_depth=7,\n",
       "                                     n_estimators=4000),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.05, 0.1, 0.5],\n",
       "                         'max_depth': [1, 7, 31, 63]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9772bec5683a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c29642668001>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{\\hat{y}_i - y_i}{y_i}\\right)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261925563827468"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_output:\n",
    "    y_pred_train = np.exp(model.predict(X_train, verbose=1)*max_log_y)\n",
    "    y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
    "    y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)\n",
    "else:\n",
    "    y_pred_train = model.predict(X_train, verbose=1)*y_std + y_mean\n",
    "    y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
    "    y_pred_test = model.predict(X_test, verbose=1)*y_std + y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1416616377810573"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "np.sqrt((((df_train['Sales'].values - y_pred_train)/df_train['Sales'].values)**2).sum()/len(y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11807734342626759"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación\n",
    "np.sqrt((((df_val['Sales'].values - y_pred)/df_val['Sales'].values)**2).sum()/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_log_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-77a06421a155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalculate_RMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-d9726d4be1b6>\u001b[0m in \u001b[0;36mcalculate_RMSE\u001b[1;34m(X, y, log_output)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_RMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmax_log_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_log_y' is not defined"
     ]
    }
   ],
   "source": [
    "calculate_RMSE(X_train, df_train['Sales'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_RMSE(X_val, df_val['Sales'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumbit a la competición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv = pd.read_csv('dataset/rossmann/sample_submission.csv')\n",
    "sample_csv['Sales'] = y_pred_test\n",
    "sample_csv.head()\n",
    "\n",
    "sample_csv.to_csv(f'submision_lightgbm_{split_type}-{log_output}-{min_child_samples}-{n_estimators}-{learning_rate}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
